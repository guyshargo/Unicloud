# -*- coding: utf-8 -*-
"""CloudPr2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_opw71iP-_V41jvaa6HfalP_4bxg7tH5
"""

!pip install firebase requests beautifulsoup4 nltk --quiet
from firebase import firebase
DB_URL = 'https://hw2-index-default-rtdb.firebaseio.com/'
FBconn = firebase.FirebaseApplication(DB_URL, None)

import time, re, nltk, requests, json
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from nltk.stem import PorterStemmer
from requests.adapters import HTTPAdapter
nltk.download('punkt', quiet=True)

ROOT_URL = "https://mqtt.org/"
MAX_PAGES = 50
CRAWL_DEPTH = 2
THREADS = 32

STOP_WORDS = {
    'a','an','the','and','or','in','on','at','of','to','for','with','by','from',
    'is','are','was','were','be','been','being','it','its','this','that','these','those',
    'as','if','but','so','such','into','about','than','then',
    'mqtt','protocol','client','server'
}

stemmer = PorterStemmer()
session = requests.Session()
adapter = HTTPAdapter(pool_connections=THREADS, pool_maxsize=THREADS)
session.mount("http://", adapter)
session.mount("https://", adapter)

def fetch_page(url):
    try:
        r = session.get(url, timeout=4)
        if r.ok and 'text/html' in r.headers.get('content-type',''):
            return url, BeautifulSoup(r.text, 'html.parser')
    except requests.RequestException:
        pass
    return url, None

def crawl(root=ROOT_URL, depth=CRAWL_DEPTH, maxp=MAX_PAGES):
    seen, queue, pages = set(), [(root, 0)], []
    while queue and len(pages) < maxp:
        batch, next_queue = queue[:THREADS], queue[THREADS:]
        queue = next_queue
        with ThreadPoolExecutor(max_workers=THREADS) as ex:
            for url, soup in ex.map(lambda u_d: fetch_page(u_d[0]), batch):
                d = dict(batch)[url]
                seen.add(url)
                if len(pages) >= maxp or soup is None:
                    continue
                pages.append((url, soup))
                if d >= depth:
                    continue
                for a in soup.find_all('a', href=True):
                    full = urljoin(url, a['href'])
                    if urlparse(full).netloc == urlparse(root).netloc and full not in seen:
                        queue.append((full, d + 1))
    return pages

def index_words(soup):
    idx = {}
    for w in re.findall(r'\w+', soup.get_text()):
        w = w.lower()
        if w not in STOP_WORDS:
            idx[w] = idx.get(w, 0) + 1
    return idx

def stemming(idx):
    out = {}
    for w, c in idx.items():
        root = stemmer.stem(w)
        out[root] = out.get(root, 0) + c
    return out

def build_inv(pages):
    inv = defaultdict(list)
    for url, soup in pages:
        for term in stemming(index_words(soup)):
            inv[term].append(url)
    return inv

pages = crawl()
inv = build_inv(pages)
trans = str.maketrans({'.':'_','#':'_','$':'_','[':'_',']':'_','/':'_'})
firebase_payload = {term.translate(trans): {"term": term, "DocIDs": urls} for term, urls in inv.items()}

FBconn.delete('/mqtt_index', None)
FBconn.patch('/mqtt_index', firebase_payload)

print(f"Uploaded {len(inv):,} unique terms from {len(pages)} pages")

def getWordCount(stemTerms, url):
   # Fetch the page
    url, soup = fetch_page(url)

    #page was fetched successfully
    if soup is None:
        return 0

    # Extract the words
    idx = index_words(soup)
    idx = stemming(idx)

    # Count the words in the query
    words_count = 0
    for stemmed_term in stemTerms:
        words_count += idx.get(stemmed_term, 0)
    return words_count

#get record based on term from the database
def get_record(term):
    # Make sure the term is Firebase-safe
    trans = str.maketrans({'.':'_','#':'_','$':'_','[':'_',']':'_','/':'_'})
    safe_term = term.translate(trans)

    # Fetch the record
    record = FBconn.get(f'/mqtt_index/{safe_term}', None)
    return record['DocIDs'] if record else []

#get page rank function
def getPageRank(urls, stemTerms):
    # Initialize ranks
    ranks = {}
    wordcnt_urls = {}

    # Calculate rank for each URL
    for url in urls:
        rank = 1
        word_counts = getWordCount(stemTerms, url)
        wordcnt_urls[url] = word_counts

        # Calculate rank based on word counts
        if word_counts > 0:
            rank = 1 / word_counts

        # Store the rank
        ranks[url] = 1 - rank

    # Sort by rank
    ranked_urls = sorted(ranks.items(), key=lambda x: x[1], reverse=True)
    # Return both the sorted ranks and the raw word counts
    return ranked_urls, wordcnt_urls

#search the database for relevent links
def search_records(query):
    query = query.strip().lower();
    process_query = query.split()
    urls = []
    stemTerms = []
    #stem the terms and get the urls
    for term in process_query:
      if (term not in STOP_WORDS):
          stemTerms.append(stemmer.stem(term))
          urls.extend(get_record(stemmer.stem(term)))

        # Remove duplicates
    urls = list(set(urls))
    return getPageRank(urls,stemTerms)



import time
from IPython.display import display, clear_output

# Tab 2: Search
# Tab 2: Raw Data with Input Field
tab2_content = widgets.Output()

search_input = widgets.Text(
    placeholder="🔍 Type to search...",
    layout=widgets.Layout(width="500px", margin="0 10px 0 0")
)

search_button = widgets.Button(
    description="Search",
    button_style="success",
    layout=widgets.Layout(width="100px")
)

search_box = HBox([search_input, search_button])

# Function to handle search
def search_data(_=None):
    query = search_input.value.strip().lower()

    with tab2_content:
        # Clear only the output without resetting the input field
        tab2_content.clear_output(wait=True)
        display(search_box)  # Keep the input visible
        # Show loading message
        print("\n🔍 Searching pages...", flush=True)
        relevant_urls, occurrences = search_records(query)

        # Clear the loading message before showing results
        tab2_content.clear_output(wait=True)
        display(search_box)

        # Show the number of results
        result_count = len(relevant_urls)
        if result_count > 0:
            print("\n" + " " * 10 + f"🔎 Found {result_count} Results" + " " * 10)
            print("-" * 50)

            for url, score in relevant_urls:
                # Print URL with occurrences and page rank
                print(f"🔗 {url}")
                print(f"    📊 Occurrences: {occurrences.get(url, 0)} | Page Rank: {score:.4f}")
                print("-" * 50)
        else:
            print("\nNo results found.")


search_button.on_click(search_data)

# Initial Data Display
with tab2_content:
    display(search_box)

!pip install paho-mqtt

import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import ipywidgets as widgets
from IPython.display import display, clear_output
import time
import random
import threading
from collections import deque
import json
import paho.mqtt.client as mqtt
from datetime import timedelta
from google.colab import files
import pandas as pd
from datetime import datetime
import openpyxl

#FBconnTerms

# Sensor Data Storage (with 'values' field)
indoor_sensors = [
    {"type":"Temperature","values": deque(maxlen=100)},
    {"type":"Humidity","values": deque(maxlen=100)},
    {"type":"Pressure","values": deque(maxlen=100)},
    {"type":"Distance","values": deque(maxlen=100)},
]

outdoor_sensors = [
    {"type":"DLIGHT","values": deque(maxlen=100)},
]

# Global Units for Each Sensor
SENSOR_UNITS = {
    "Temperature": "°C",
    "Humidity": "%",
    "Pressure": "hPa",
    "Distance": "mm",
    "DLIGHT": "Lux"
}

# Global Thresholds
IRREGULAR_THRESHOLDS = {
    "Temperature": (10, 30),
    "Humidity": (60, 90),
    "Pressure": (990, 1030),
    "Distance": (500, 900),
    "DLIGHT": (0, 100000)
}

# Plotting Function
def plotSensor(sensor_type, x,y, widget):
    fig, ax = plt.subplots(figsize=(5, 3))
    # Correct get call with None for the node name

    min_val, max_val = IRREGULAR_THRESHOLDS[sensor_type]
    average_value = sum(y) / len(y) if y else 0
    current_value = y[-1] if y else 0
    is_irregular = average_value < min_val or average_value > max_val
    font_color = '#FF3232' if is_irregular else '#00C717'
    # Plot the data
    ax.plot(x, y, color=font_color, linewidth=2)
    ax.set_title(f"{sensor_type} ({current_value} {SENSOR_UNITS[sensor_type]})", fontsize=14, color=font_color)

    # Set x-axis ticks to show all 6 labels
    ax.set_xticks(x)
    ax.tick_params(axis='x', labelrotation=30)
    ax.grid(True)

    plt.tight_layout()
    with widget:
        clear_output(wait=True)
        plt.show()


# Create Sensor Widgets
indoor_sensor_widgets = {sensor["type"]: widgets.Output() for sensor in indoor_sensors}
outdoor_sensor_widgets = {sensor["type"]: widgets.Output() for sensor in outdoor_sensors}

# Create Grids
def createGrid(sensor_dict, widget_dict):
    grid = widgets.GridBox(
        children=[widget_dict[sensor["type"]] for sensor in sensor_dict],
        layout=widgets.Layout(
            grid_template_columns='repeat(2, minmax(0, 1fr))',
            grid_gap='10px 10px',
            align_items='flex-start',
            justify_items='center'
        )
    )
    return grid
# Create the indoor and outdoor grids
indoor_grid = createGrid(indoor_sensors, indoor_sensor_widgets)
outdoor_grid = createGrid(outdoor_sensors, outdoor_sensor_widgets)


# Activation Function
def activateSensors(sensor_dict, widget_dict, location):
    for sensor in sensor_dict:
        sensor_type = sensor["type"]

        # Fetch the last 6 values from Firebase
        history = FBconn.get('/Sensors', f'{location}/{sensor_type}/history')

        # If history is empty, generate fake data
        if not history:
            generateFakeData(sensor_dict, location)
            history = FBconn.get('/Sensors', f'{location}/{sensor_type}/history')

        # Extract timestamps and values
        else:
            x, y = zip(*[(item["timestamp"], item["value"]) for item in history.values()])
            if (len(x) > 6):
              x = x[:6]
              y = y[:6]
            # Plot the data
            with widget_dict[sensor_type]:
                clear_output(wait=True)
                plotSensor(sensor_type, x, y, widget_dict[sensor_type])



# Fake Data Generation (with Firebase Save)
def generateFakeData(sensors, location):
    for _ in range(10):


        for sensor in sensors:
            now = datetime.now().strftime('%H:%M:%S')
            sensor_type = sensor["type"]

            # Generate random values
            if sensor_type == "Temperature":
                value = round(random.uniform(20, 30), 2)
            elif sensor_type == "Humidity":
                value = random.randint(60, 90)
            elif sensor_type == "Pressure":
                value = random.randint(990, 1100)
            elif sensor_type == "Distance":
                value = random.randint(100, 900)
            elif sensor_type == "DLIGHT":
                value = random.randint(1000, 1500)

            # Append to local history
            sensor["values"].append((now, value))

            # Save to Firebase
            FBconn.post(f'/Sensors/{location}/{sensor_type}/history', {
                "timestamp": now,
                "value": value
            })

            # Update the latest value in Firebase
            FBconn.put(f'/Sensors/{location}/{sensor_type}', "latest", {
                "timestamp": now,
                "value": value
            })



# Real Data Handler
def on_message(client, userdata, msg):

    topic = msg.topic

    try:
        data = json.loads(msg.payload.decode())
        now = datetime.now().strftime('%H:%M:%S')
        # Indoor Sensor Data Handling
        if topic == "braude/D106/indoor":
            for sensor in indoor_sensors:
                sensor_type = sensor["type"]
                if sensor_type in data:
                    value = float(data[sensor_type])
                    timestamped_value = {"timestamp": now, "value": value}
                    # Add to the local sensor history
                    sensor["values"].append((now, value))

                    # Append to the history in Firebase (value as key)
                    FBconn.post(f'/Sensors/indoor/{sensor_type}/history', {
                        "timestamp": now,
                        "value": value
                    })
                    FBconn.put(f'/Sensors/indoor/{sensor_type}', "latest", timestamped_value)
            activateSensors(indoor_sensors, indoor_sensor_widgets, "indoor")

        # Outdoor Sensor Data Handling
        elif topic == "braude/D106/outdoor":
            for sensor in outdoor_sensors:
                sensor_type = sensor["type"]
                if sensor["type"] == "DLIGHT" and "DLIGHT" in data:
                    value = float(data["DLIGHT"])
                    timestamped_value = {"timestamp": now, "value": value}
                    # Add to the local sensor history
                    sensor["values"].append((now, value))
                    # Save to Firebase
                    FBconn.post(f'/Sensors/outdoor/{sensor_type}/history', {
                        "timestamp": now,
                        "value": value
                    })
                    # Update the latest value in Firebase

                    FBconn.put(f'/Sensors/outdoor/{sensor_type}', "latest", timestamped_value)
            activateSensors(outdoor_sensors, outdoor_sensor_widgets, "outdoor")

    except json.JSONDecodeError:
        print("Received invalid JSON data")

# MQTT Connection Attempt
def start_mqtt(topic):
    try:
        topic = f'braude/D106/{topic}'
        client = mqtt.Client()
        client.on_message = on_message
        client.connect("test.mosquitto.org", 1883, 60)
        client.subscribe(topic)

        print(f"Successfully connected to MQTT topic: {topic}")

        # Run for 5 seconds, then stop
        start_time = datetime.now()
        while (datetime.now() - start_time).seconds < 20:
            client.loop_read()

    except Exception as e:
        print(f"MQTT connection failed: {e}")

start_mqtt("indoor")
start_mqtt("outdoor")


tab5_content = widgets.Output()

# Use tab5_content for the Sensors tab
tab5_content = widgets.VBox([
    widgets.HTML("<h3>Indoor Sensors</h3>"),
    indoor_grid,
    widgets.HTML("<h3>Outdoor Sensors</h3>"),
    outdoor_grid
])

# Tab 3: Statistics
import matplotlib.pyplot as plt
import ipywidgets as widgets
from IPython.display import display
import pandas as pd
from datetime import datetime
from google.colab import files
import openpyxl

# Constants
x_range = 25
step = 4

# Color map for the graphs
colorMap = {
    # RED
    'Temperature': {
        'average': '#FF0000',
        'normalized': '#FF6666',
        'absolute': '#FF9999'
    },
    # BLUE
    'Humidity': {
        'average': '#0066CC',
        'normalized': '#66B2FF',
        'absolute': '#99CCFF'
    },
    # GREEN
    'Pressure': {
        'average': '#009900',
        'normalized': '#66CC66',
        'absolute': '#99CC99'
    },
    # PURPLE
    'Distance': {
        'average': '#800080',
        'normalized': '#B366FF',
        'absolute': '#D999FF'
    },
    # YELLOW
    'DLIGHT': {
        'average': '#FFD700',
        'normalized': '#FFE44D',
        'absolute': '#FFEB99'
    },
    # GRAY
    'Default': '#FEFEFE'
}

""" Get sensors """
def get_sensor_data():
    sensor_data = []
    sensor_model = {
        "type": None,
        "values": []
    }

    try:
        result = FBconn.get('/Sensors/', None)
        for location in result.keys():
            for sensor_type, sensor_info in result[location].items():
                sensor_copy = sensor_model.copy()
                sensor_copy['type'] = sensor_type

                # Reset values array for each sensor
                sensor_copy['values'] = []

                for record_id, record in sensor_info['history'].items():
                    sensor_copy['values'].append(record['value'])

                sensor_data.append(sensor_copy)
    except Exception as e:
        print(f"Error getting sensors: {e}")
    return sensor_data

""" Create the checkboxes """
def create_checkboxes():
    sensor_data = get_sensor_data()

    # Get unique sensor types
    sensor_types = []
    for sensor in sensor_data:
        if sensor['type'] not in sensor_types:
            sensor_types.append(sensor['type'])

    # Create checkboxes for each sensor type
    check_options = {sensor: widgets.Checkbox(value=True, description=sensor) for sensor in sensor_types}
    all_option = widgets.Checkbox(value=True, description='All')

    def all_checkbox_option(event):
        value = event.new
        for checkbox in check_options.values():
            checkbox.value = value

    all_option.observe(all_checkbox_option, names='value')

    # Create the HBox with all checkboxes
    checkboxes = widgets.HBox([all_option] + list(check_options.values()))
    return checkboxes

""" Export the data to an excel file """
def export_to_excel(sensor_types):
    if not sensor_types:
        print("No sensors selected for export")
        return

    # Create Excel file
    now = datetime.now()
    timestamp = f"{now.day}{now.month}{now.year}_{now.hour}:{now.minute}:{now.second}"
    filename = f"sensor_statistics_{timestamp}.xlsx"

    try:
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # Create a new workbook and worksheet
            workbook = writer.book
            worksheet = workbook.create_sheet('Sensor Statistics')

            # Write headers
            col = 1
            for i, sensor_type in enumerate(sensor_types):
                # Find the sensor
                sensor_data = get_sensor_data()
                sensor = None
                for s in sensor_data:
                    if s["type"] == sensor_type:
                        sensor = s
                        break

                if sensor:
                    # Add a spacer column between sensor types (except before the first one)
                    if i > 0:
                        # Merge the spacer column
                        worksheet.merge_cells(start_row=1, start_column=col, end_row=26, end_column=col)
                        cell = worksheet.cell(row=1, column=col)
                        cell.value = ""  # Empty spacer
                        cell.fill = openpyxl.styles.PatternFill(start_color="E0E0E0", end_color="E0E0E0", fill_type="solid")
                        col += 1

                    # Calculate all the statistics
                    averages = average_by_x_values(sensor['values'])
                    normalized = calculate_normalized_changes(sensor['values'])
                    absolute = calculate_absolute_changes(sensor['values'])

                    # Get colors for this sensor type
                    colors = colorMap[sensor_type]

                    # Write sensor type header
                    worksheet.merge_cells(start_row=1, start_column=col, end_row=1, end_column=col+3)
                    cell = worksheet.cell(row=1, column=col)
                    cell.value = sensor_type
                    cell.alignment = openpyxl.styles.Alignment(horizontal='center', vertical='center')
                    cell.font = openpyxl.styles.Font(bold=True, size=12)
                    cell.fill = openpyxl.styles.PatternFill(start_color=colors['average'].lstrip('#'), end_color=colors['average'].lstrip('#'), fill_type="solid")
                    cell.font = openpyxl.styles.Font(color="000000", bold=True, size=12)

                    # Write section headers
                    headers = ['Seg.', 'Avg.', 'Normal', 'Absolute']
                    for j, header in enumerate(headers):
                        cell = worksheet.cell(row=2, column=col+j)
                        cell.value = header
                        cell.font = openpyxl.styles.Font(bold=True)
                        cell.fill = openpyxl.styles.PatternFill(start_color=colors['normalized'].lstrip('#'), end_color=colors['normalized'].lstrip('#'), fill_type="solid")
                        cell.font = openpyxl.styles.Font(color="000000", bold=True)
                        cell.alignment = openpyxl.styles.Alignment(horizontal='center')

                    # Write data
                    for row in range(x_range):
                        # Segment number
                        cell = worksheet.cell(row=row+3, column=col)
                        cell.value = row+1
                        cell.alignment = openpyxl.styles.Alignment(horizontal='center')

                        # Average value
                        cell = worksheet.cell(row=row+3, column=col+1)
                        cell.value = averages[row]
                        cell.fill = openpyxl.styles.PatternFill(start_color=colors['average'].lstrip('#'), end_color=colors['average'].lstrip('#'), fill_type="solid")
                        cell.font = openpyxl.styles.Font(color="000000")

                        # Normalized value
                        cell = worksheet.cell(row=row+3, column=col+2)
                        cell.value = normalized[row]
                        cell.fill = openpyxl.styles.PatternFill(start_color=colors['normalized'].lstrip('#'), end_color=colors['normalized'].lstrip('#'), fill_type="solid")
                        cell.font = openpyxl.styles.Font(color="000000")

                        # Absolute value
                        cell = worksheet.cell(row=row+3, column=col+3)
                        cell.value = absolute[row]
                        cell.fill = openpyxl.styles.PatternFill(start_color=colors['absolute'].lstrip('#'), end_color=colors['absolute'].lstrip('#'), fill_type="solid")
                        cell.font = openpyxl.styles.Font(color="000000")

                    # Add borders to all cells
                    for row in range(1, x_range + 3):
                        for c in range(col, col + 4):
                            cell = worksheet.cell(row=row, column=c)
                            cell.border = openpyxl.styles.Border(
                                left=openpyxl.styles.Side(style='thin'),
                                right=openpyxl.styles.Side(style='thin'),
                                top=openpyxl.styles.Side(style='thin'),
                                bottom=openpyxl.styles.Side(style='thin')
                            )

                    col += 4

            # Remove the default sheet
            if 'Sheet' in workbook.sheetnames:
                del workbook['Sheet']

            # Auto-adjust column widths
            for column in worksheet.columns:
                max_length = 0
                column = [cell for cell in column]
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = (max_length + 2)
                worksheet.column_dimensions[openpyxl.utils.get_column_letter(column[0].column)].width = adjusted_width

        print(f"Data exported successfully to {filename}")
        files.download(filename)
    except Exception as e:
        print(f"Error saving file: {str(e)}")

""" Get the selected sensors """
def get_selected_sensors(checkboxes):
    sensor_types = []
    # Skip the first checkbox (All) when collecting sensor types
    for i in range(1, len(checkboxes.children)):
        if checkboxes.children[i].value:
            sensor_types.append(checkboxes.children[i].description)
    if 'All' in sensor_types:
        sensor_types = [checkboxes.children[i].description for i in range(len(checkboxes.children))]
    return sensor_types

""" Create the statistics tab """
def create_statistics_tab():
    output = widgets.Output()

    # Create checkboxes for sensor selection
    checkboxes = create_checkboxes()

    # Create button
    create_button = widgets.Button(description='Make Graphs')
    create_button.on_click(lambda b: create_button_click(output, colorMap, get_selected_sensors(checkboxes)))

    # Clear button
    clear_button = widgets.Button(description='Clear Graphs')
    clear_button.on_click(lambda b: output.clear_output())

    # Excel export button
    excel_button = widgets.Button(description='Export to Excel')
    excel_button.on_click(lambda b: export_to_excel(get_selected_sensors(checkboxes)))

    # Layout
    buttons_box = widgets.HBox([create_button, clear_button, excel_button])
    tab_content = widgets.VBox([checkboxes, buttons_box, output])

    return tab_content

""" Handle the click event """
def create_button_click(output, colorMap, sensor_types):
    sensor_data = get_sensor_data()
    if not sensor_types:
        print("No sensors selected for graphing")
        return

    with output:
        output.clear_output()
        fig = plt.figure(figsize=(25, 22))
        grid = fig.add_gridspec(4, 5, hspace=0.4, wspace=0.3)

        # Collect all selected sensors
        selected_sensors = []
        for sensor_type in sensor_types:
            for sensor in sensor_data:
                if sensor["type"] == sensor_type:
                    selected_sensors.append(sensor)
                    break

        if not selected_sensors:
            print("No sensor data available")
            return

        # Plot graphs
        plot_all_graphs(fig, grid, selected_sensors, colorMap)

        # Plot heatmaps if we have at least 2 sensors
        if len(selected_sensors) >= 2:
            plot_all_heatmaps(fig, grid, selected_sensors, sensor_types)

        plt.tight_layout()
        plt.show()

""" Plot the graphs """
def plot_all_graphs(fig, grid, sensors, colorMap):
    plot_types = ['average', 'normalized', 'absolute']
    x_values = range(1, x_range + 1)

    for row, plot_type in enumerate(plot_types):
        for col, sensor in enumerate(sensors):
            ax = fig.add_subplot(grid[row, col])
            sensor_type = sensor['type']

            color_by_type = colorMap[sensor_type]

            color = color_by_type[plot_type]

            if plot_type == 'average':
                plot_average_graph(ax, sensor, x_values, color)
            elif plot_type == 'normalized':
                plot_normalized_graph(ax, sensor, x_values, color)
            elif plot_type == 'absolute':
                plot_absolute_graph(ax, sensor, x_values, color)

""" Plot the heatmaps """
def plot_all_heatmaps(fig, grid, sensors, sensor_types):
    if len(sensors) < 2:
        return

    inc = 0
    if 'Temperature' in sensor_types and 'Humidity' in sensor_types:
        ax_temp_humid = fig.add_subplot(grid[3, inc:inc+2])
        plot_diff_heatmap(ax_temp_humid, sensors, 'Temperature','Humidity')
        inc += 2

    if 'Pressure' in sensor_types and 'Humidity' in sensor_types:
        ax_press_humid = fig.add_subplot(grid[3, inc:inc+2])
        plot_diff_heatmap(ax_press_humid, sensors, 'Pressure','Humidity')

""" Calculate the average of the values """
def average_by_x_values(values):
    averages = []

    for i in range(x_range):
        start_idx = i * step
        end_idx = start_idx + step
        segment = values[start_idx:end_idx]
        if segment:
            averages.append(sum(segment) / len(segment))
        else:
            averages.append(0)
    return averages

""" Calculate the absolute changes of the values """
def calculate_absolute_changes(values):
    averages = average_by_x_values(values)
    # Get the first measurement value
    initial_value = values[0] if values else 0
    changes = []
    for avg in averages:
        changes.append(avg - initial_value)
    return changes

""" Calculate the normalized changes of the values by segments """
def calculate_normalized_changes(values):
    averages = average_by_x_values(values)
    # Get the first measurement value
    initial_value = values[0] if values else 0
    normalized = []
    for avg in averages:
        if initial_value != 0:
            normalized.append(((avg - initial_value) / initial_value) * 100)
        else:
            normalized.append(0)
    return normalized

""" Plot the graph """
def plot_graph(ax, y_values, x_values, color, title, xlabel, ylabel, plot_type, sensor_type):
    if plot_type == 'line':
        ax.plot(x_values, y_values, marker='o', color=color, label=sensor_type)
    elif plot_type == 'bar':
        ax.bar(x_values, y_values, color=color, alpha=0.7, label=sensor_type)
    segment_avg = sum(y_values) / len(y_values)
    ax.axhline(y=segment_avg, color='black', linestyle='-', label=f'Avg: {segment_avg:.2f}')
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.grid(True)
    ax.legend()

""" Plot the average graph """
def plot_average_graph(ax, sensor, x_values, color):
    averages = average_by_x_values(sensor['values'])
    title = f"{sensor['type']} - Segment Averages"
    x_label = "Segment"
    y_label = "Average Value"
    plot_type = "line"
    plot_graph(ax, averages, x_values, color, title, x_label, y_label, plot_type, sensor['type'])

""" Plot the absolute graph """
def plot_absolute_graph(ax, sensor, x_values, color):
    changes = calculate_absolute_changes(sensor['values'])
    title = f"{sensor['type']} - Absolute Changes"
    x_label = "Segment"
    y_label = "Change from Initial"
    plot_type = "bar"
    plot_graph(ax, changes, x_values, color, title, x_label, y_label, plot_type, sensor['type'])

""" Plot the normalized graph """
def plot_normalized_graph(ax, sensor, x_values, color):
    changes = calculate_normalized_changes(sensor['values'])
    title = f"{sensor['type']} - Normalized Changes"
    x_label = "Segment"
    y_label = "Change from Initial (%)"
    plot_type = "line"
    plot_graph(ax, changes, x_values, color, title, x_label, y_label, plot_type, sensor['type'])

""" Plot the difference heatmap between two sensors """
def plot_diff_heatmap(ax, sensors, sensor1, sensor2):
    sensor1 = get_sensor(sensors, sensor1)
    sensor2 = get_sensor(sensors, sensor2)

    sensor1_normalized = calculate_normalized_changes(sensor1['values'])
    sensor2_normalized = calculate_normalized_changes(sensor2['values'])

    sensors_diff = [abs(sensor1_normalized[i] - sensor2_normalized[i]) for i in range(x_range)]

    # Normalize the difference
    max_diff = max(sensors_diff)
    if max_diff > 0:
        sensors_diff = [diff/max_diff for diff in sensors_diff]

    # Create heatmap using matplotlib
    im = ax.imshow([sensors_diff],
                  cmap='YlOrRd',
                  aspect='auto',
                  extent=[0.5, x_range + 0.5, 0.5, 1.5])

    # Add colorbar
    plt.colorbar(im, ax=ax)

    # Set labels and title
    ax.set_xticks(range(1, x_range + 1))
    ax.set_yticks([])
    ax.set_title(f"{sensor1['type']} - {sensor2['type']} Normalized Difference")
    ax.set_xlabel("Segment")

""" Plot a row of graphs by type of sensor and plot type """
def plot_graphs_by_type(ax, fig, gs, sensors, colorMap, show):
    x_values = range(1, x_range + 1)

    for i, sensor in enumerate(sensors):
        ax = fig.add_subplot(gs[0, i])
        sensor_type = sensor['type']
        color = colorMap[sensor_type]['average']

        if show == 'average':
            plot_average_graph(ax, sensor, x_values, color)
        elif show == 'normalized':
            plot_normalized_graph(ax, sensor, x_values, color)
        elif show == 'absolute':
            plot_absolute_graph(ax, sensor, x_values, color)
    return ax

""" Get the sensor by type """
def get_sensor(sensors, sensor_type):
    for sensor in sensors:
        if sensor['type'] == sensor_type:
            return sensor
    return None

tab3_content = create_statistics_tab()

from ipywidgets import widgets, VBox, HBox, Output, Label, Textarea, Layout, Dropdown, Button
from IPython.display import display, Javascript, HTML, clear_output
import pandas as pd
from datetime import datetime
from ipywidgets import Layout


# Task Manager Data
task_data = {
    "T001": {"assignee": "John Doe", "title": "Sensor Calibration", "status": "To Do", "priority": "High", "description": "Calibrate all sensors in Zone A to meet accuracy standards.", "start_date": "2025-05-01", "due_date": "2025-06-01"},
    "T002": {"assignee": "Jane Smith", "title": "Data Logging", "status": "In Progress", "priority": "Medium", "description": "Ensure data from all pressure sensors is logged every 10 seconds.", "start_date": "2025-04-15", "due_date": "2025-05-15"},
    "T003": {"assignee": "Alice Brown", "title": "Signal Processing", "status": "Done", "priority": "Low", "description": "Filter noise from sensor input using a moving average algorithm.", "start_date": "2025-03-10", "due_date": "2025-04-10"},
    "T004": {"assignee": "Bob White", "title": "System Monitoring", "status": "In Progress", "priority": "High", "description": "Track anomalies in sensor data and report threshold violations.", "start_date": "2025-04-20", "due_date": "2025-05-20"},
}

for task_id, data in task_data.items():
    FBconn.put(f'/TaskManager/', task_id, data)

graph_checkboxes = create_checkboxes()
graph_selector   = VBox([
    Label("📊 Select sensors for Statistics"),
    graph_checkboxes
], layout=Layout(width='100%', margin='10px 0 0 0'))


# Function to get next Task ID
def get_next_task_id():
    tasks = FBconn.get('/TaskManager/', None)
    if not tasks:
        return "T001"
    try:
        ids = [int(k[1:]) for k in tasks.keys() if k.startswith("T") and k[1:].isdigit()]
        next_id = max(ids) + 1
        return f"T{next_id:03d}"
    except:
        return "T001"

def get_workers():
    try:
        workers = FBconn.get('/workers/', None)
        return workers
    except:
        return []


# Tab 1: Manager Dashboard
tab1_content = widgets.Output()

with tab1_content:
    workers = get_workers()
    sensor_data = get_sensor_data()
    sensor_types = [sensor['type'] for sensor in sensor_data]
    task_data = FBconn.get('/TaskManager/', None)

    # Task Manager Display
    task_df = pd.DataFrame.from_dict(task_data, orient='index')
    task_df.index.name = "Task ID"
    task_df = task_df.reset_index()
    task_df.index = range(1, len(task_df) + 1)
    task_df = task_df[["Task ID", "assignee", "title", "status", "priority", "start_date", "due_date", "description"]]
    task_output = Output()
    with task_output:
        display(HTML(
            task_df.style
            .set_table_attributes('class="dataframe taskmanager"')
            .set_table_styles([
                {'selector': 'th', 'props': [('text-align', 'center'), ('vertical-align', 'middle')]},
                {'selector': 'td', 'props': [('text-align', 'center'), ('vertical-align', 'middle')]},
            ], overwrite=False)
            .to_html()
        ))

    # Task Assignment Inputs
    task_id_input = Textarea(
        value=get_next_task_id(),
        disabled=True,
        layout=Layout(width='150px', height='33px')
    )

    worker_names = [worker['name'] for worker in workers]
    assigned_dropdown = Dropdown(
        options=worker_names,
        description='Assign to:',
        layout=Layout(width='50%')
    )

    sensor_names = [sensor['type'] + ' Sensor' for sensor in sensor_data]
    subject_dropdown_task = Dropdown(
        options=sensor_names,
        description='Subject:',
        layout=Layout(width='50%')
    )

    status_dropdown = Dropdown(
        options=["To Do", "In Progress", "Done"],
        description='Status:',
        layout=Layout(width='50%')
    )

    priority_dropdown = Dropdown(
        options=["Low", "Medium", "High"],
        description='Priority:',
        layout=Layout(width='50%')
    )

    task_details_textarea = Textarea(
    placeholder='Enter task details or description...',
    description='Details:',
    layout=Layout(width='100%', height='60px')
    )

    save_task_button = Button(
        description="Add Task",
        button_style='success',
        layout=Layout(height='60px')
    )

    # Date Picker Inputs
    start_date_input = widgets.DatePicker(
      description="Start Date",
      value=datetime.today().date(),
      layout=Layout(width='50%')
    )

    due_date_input = widgets.DatePicker(
      description="Due Date",
      value=datetime.today().date(),
      layout=Layout(width='50%')
    )
    task_log_output = Output()

    # Modified Save Task Function
    def save_task(_):
      task_id = task_id_input.value.strip()
      assigned_to = assigned_dropdown.value
      subject = subject_dropdown_task.value
      status = status_dropdown.value
      priority = priority_dropdown.value
      details = task_details_textarea.value.strip()
      start_date = start_date_input.value
      due_date = due_date_input.value

      if not task_id:
        with task_log_output:
            clear_output()
            print("❌ Task ID cannot be empty.")
        return

      new_task = {
        "assignee": assigned_to,
        "description": details,
        "due_date": due_date.strftime('%Y-%m-%d'),
        "id": task_id,
        "priority": priority,
        "start_date": start_date.strftime('%Y-%m-%d'),
        "status": status,
        "title": subject,
      }

      FBconn.put('/TaskManager/', new_task['id'], new_task)

      updated_task_data = FBconn.get('/TaskManager/', None)
      updated_task_df = pd.DataFrame.from_dict(updated_task_data, orient='index').reset_index()
      updated_task_df.rename(columns={"index": "Task ID"}, inplace=True)
      updated_task_df = updated_task_df[["Task ID", "assignee", "title", "status", "priority", "start_date", "due_date", "description"]]

      with task_output:
        clear_output()
        display(HTML(
            updated_task_df.style
            .set_table_attributes('class="dataframe taskmanager"')
            .set_table_styles([
                {'selector': 'th', 'props': [('text-align', 'center'), ('vertical-align', 'middle')]},
                {'selector': 'td', 'props': [('text-align', 'center'), ('vertical-align', 'middle')]},
            ], overwrite=False)
            .to_html()
        ))

      with task_log_output:
        clear_output()
        print(f"✅ Task {task_id} assigned to {assigned_to} with subject '{subject}', priority {priority}, and status '{status}'.")
      task_id_input.value = get_next_task_id()

    save_task_button.on_click(save_task)

    # Task Assignment Form
    task_assignment_form = VBox([
      Label("➕ Assign New Task"),

      HBox([
        Label("Task ID:", layout=Layout(min_width='90px')),
        task_id_input
      ], layout=Layout(align_items='center', justify_content='flex-start')),

      HBox([assigned_dropdown, subject_dropdown_task], layout=Layout(align_items='center', justify_content='flex-start')),
      HBox([status_dropdown, priority_dropdown], layout=Layout(align_items='center', justify_content='flex-start')),

      # Add Date Fields
      HBox([
        start_date_input, due_date_input
      ], layout=Layout(align_items='center', justify_content='flex-start')),

      HBox([task_details_textarea, save_task_button], layout=Layout(align_items='center', justify_content='flex-start')),
      task_log_output
    ])

    # Sensor Feed
    sensor_output = Output()
    with sensor_output:
        print("Waiting for sensor data...")

    # Alerts
    alerts_output = Output()
    with alerts_output:
        print("C2 - Sensor is down!\nB3 - Sensor delay detected.")

    # Notes
    notes_textarea = Textarea(
        placeholder='Enter your notes here...',
        description='Notes:',
        layout=Layout(width='100%', height='100px', overflow='hidden')
    )
    subject_dropdown_note = Dropdown(
      options=["Sensor Calibration", "Data Logging", "Signal Processing", "System Monitoring", "Maintenance"],
      description='Subject:',
      layout=Layout(width='50%')
    )
    employee_dropdown = Dropdown(
        options=worker_names,
        description='Assign to:',
        layout=Layout(width='50%')
    )
    save_button = Button(
        description="💾 Save Note",
        button_style='info'
    )

    save_log_output = Output()

    def get_employee_id(name):
      return name.lower().replace(" ", "_")

    def save_note(_):
      emp_name = employee_dropdown.value
      emp_id = get_employee_id(emp_name)
      note = notes_textarea.value.strip()
      subject = subject_dropdown_note.value

      if note:
          timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
          data = {
              "note": note,
              "subject": subject,
              "timestamp": timestamp
          }
          worker_notes = FBconn.get(f'/Notes', {emp_id}) or []
          worker_notes.append(data)
          result = FBconn.put(f'/Notes', {emp_id}, worker_notes)

          with save_log_output:
              clear_output()
              if result:
                  print(f"✅ Note saved for {emp_name} at {timestamp}:\n{note}")
              else:
                  print("❌ Failed to save note. Check Firebase connection.")

      notes_textarea.value = ''
    save_button.on_click(save_note)

    # Task Manager Layout
    task_manager_section = HBox([
      VBox([task_output], layout=Layout(width='50%', margin='0 20px 0 0')),  # Task Manager Table
      VBox([task_assignment_form], layout=Layout(width='50%'))  # Assign New Task Form
    ], layout=Layout(width='100%'))


    # Dashboard Layout
    row1 = HBox([task_manager_section], layout=Layout(align_items='flex-start', width="100%"))

    row2 = HBox([
        VBox([Label("📡 Sensor Activity Feed"), sensor_output], layout=Layout(width='70%')),
        VBox([Label("🚨 Alerts / Warnings"), alerts_output], layout=Layout(width='30%'))
    ], layout=Layout(align_items='flex-start'))

    notes = VBox([
      Label("📝 Notes / Messages"),
      HBox([
        VBox([notes_textarea], layout=Layout(width='70%')),
        VBox([employee_dropdown, subject_dropdown_note, save_button], layout=Layout(width='30%', align_items='flex-start', justify_content='flex-start'))
      ]),
      save_log_output
    ], layout=Layout(width='100%'))

    display(VBox([row1, row2, graph_selector, notes]))

# Tab 4: Leaderboard
tab4_content = widgets.Output()
with tab4_content:
    workers = get_workers()
    workers.sort(key=lambda w: w['score'])
    workers.reverse()

    # Scoreboard Display
    leaderboard_df = pd.DataFrame(workers)
    leaderboard_df.index = range(1, len(leaderboard_df) + 1)  # Start rank from 1
    leaderboard_df.index.name = "Rank"

    # Add Award Column (trophies for top 3)
    trophies = {1: "🏆", 2: "🥈", 3: "🥉"}
    leaderboard_df["Award"] = [trophies.get(i, "") for i in leaderboard_df.index]

    # Reorder columns to show Rank, Award, Name, Email, and other data
    cols = ["Award", "name", "email"] + [col for col in leaderboard_df.columns if col not in ["Award", "name", "email"]]
    leaderboard_df = leaderboard_df[cols]

    leaderboard_output = Output()
    with leaderboard_output:
        display(HTML(
            leaderboard_df.style
            .hide(axis='index')
            .set_table_attributes('class="dataframe leaderboard"')
            .set_table_styles([
                {'selector': 'th', 'props': [('text-align', 'center'), ('vertical-align', 'middle'), ('font-size', '18px')]},
                {'selector': 'td', 'props': [('text-align', 'center'), ('vertical-align', 'middle'), ('font-size', '16px')]},
            ], overwrite=False)
            .to_html()
        ))

    # Scrollable Area for leaderboard Table
    scrollable_area = widgets.Box([leaderboard_output],
        layout=Layout(overflow_y='scroll', width='100%', height='400px', border='1px solid lightgray'))

    display(VBox([Label("📋 Employees Leaderboard"), scrollable_area], layout=Layout(width='100%')))

# Display the main tabs
tabs = widgets.Tab(children=[tab1_content, tab2_content, tab3_content, tab4_content, tab5_content])
tabs.set_title(0, 'Dashboard')
tabs.set_title(1, 'Search')
tabs.set_title(2, 'Statistics')
tabs.set_title(3, 'Leaderboard')
tabs.set_title(4, 'Sensors')
display(tabs)